{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6fca250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import torch\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de77ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGE_NUMBER = 1e10\n",
    "TINY_NUMBER = 1e-6  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541c3686",
   "metadata": {},
   "source": [
    "# Ray Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ee36ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from autonomousvision/giraffe\n",
    "\n",
    "# 0.\n",
    "def to_pytorch(tensor, return_type=False):\n",
    "    ''' Converts input tensor to pytorch.\n",
    "    Args:\n",
    "        tensor (tensor): Numpy or Pytorch tensor\n",
    "        return_type (bool): whether to return input type\n",
    "    '''\n",
    "    is_numpy = False\n",
    "    if type(tensor) == np.ndarray:\n",
    "        tensor = torch.from_numpy(tensor).float()\n",
    "        is_numpy = True\n",
    "    tensor = tensor.clone()\n",
    "    if return_type:\n",
    "        return tensor, is_numpy\n",
    "    return tensor\n",
    "\n",
    "# 1. get camera intrinsic\n",
    "def get_camera_mat(fov=49.13, invert=True):\n",
    "    # fov = 2 * arctan( sensor / (2 * focal))\n",
    "    # focal = (sensor / 2)  * 1 / (tan(0.5 * fov))\n",
    "    # in our case, sensor = 2 as pixels are in [-1, 1]\n",
    "    focal = 1. / np.tan(0.5 * fov * np.pi/180.)\n",
    "    focal = focal.astype(np.float32)\n",
    "    mat = torch.tensor([\n",
    "        [focal, 0., 0., 0.],\n",
    "        [0., focal, 0., 0.],\n",
    "        [0., 0., 1, 0.],\n",
    "        [0., 0., 0., 1.]\n",
    "    ]).reshape(1, 4, 4)\n",
    "\n",
    "    if invert:\n",
    "        mat = torch.inverse(mat)\n",
    "    return mat\n",
    "\n",
    "# 2. get camera position with camera pose (theta & phi)\n",
    "def to_sphere(u, v):\n",
    "    theta = 2 * np.pi * u\n",
    "    phi = np.arccos(1 - 2 * v)\n",
    "    cx = np.sin(phi) * np.cos(theta)\n",
    "    cy = np.sin(phi) * np.sin(theta)\n",
    "    cz = np.cos(phi)\n",
    "    return np.stack([cx, cy, cz], axis=-1)\n",
    "\n",
    "# 3. get camera coordinate system assuming it points to the center of the sphere\n",
    "def look_at(eye, at=np.array([0, 0, 0]), up=np.array([0, 0, 1]), eps=1e-5,\n",
    "            to_pytorch=True):\n",
    "    at = at.astype(float).reshape(1, 3)\n",
    "    up = up.astype(float).reshape(1, 3)\n",
    "    eye = eye.reshape(-1, 3)\n",
    "    up = up.repeat(eye.shape[0] // up.shape[0], axis=0)\n",
    "    eps = np.array([eps]).reshape(1, 1).repeat(up.shape[0], axis=0)\n",
    "\n",
    "    z_axis = eye - at\n",
    "    z_axis /= np.max(np.stack([np.linalg.norm(z_axis,\n",
    "                                              axis=1, keepdims=True), eps]))\n",
    "\n",
    "    x_axis = np.cross(up, z_axis)\n",
    "    x_axis /= np.max(np.stack([np.linalg.norm(x_axis,\n",
    "                                              axis=1, keepdims=True), eps]))\n",
    "\n",
    "    y_axis = np.cross(z_axis, x_axis)\n",
    "    y_axis /= np.max(np.stack([np.linalg.norm(y_axis,\n",
    "                                              axis=1, keepdims=True), eps]))\n",
    "\n",
    "    r_mat = np.concatenate(\n",
    "        (x_axis.reshape(-1, 3, 1), y_axis.reshape(-1, 3, 1), z_axis.reshape(\n",
    "            -1, 3, 1)), axis=2)\n",
    "\n",
    "    if to_pytorch:\n",
    "        r_mat = torch.tensor(r_mat).float()\n",
    "\n",
    "    return r_mat\n",
    "\n",
    "# 5. arange 2d array of pixel coordinate and give depth of 1\n",
    "def arange_pixels(resolution=(128, 128), batch_size=1, image_range=(-1., 1.),\n",
    "                  subsample_to=None, invert_y_axis=False):\n",
    "    ''' Arranges pixels for given resolution in range image_range.\n",
    "    The function returns the unscaled pixel locations as integers and the\n",
    "    scaled float values.\n",
    "    Args:\n",
    "        resolution (tuple): image resolution\n",
    "        batch_size (int): batch size\n",
    "        image_range (tuple): range of output points (default [-1, 1])\n",
    "        subsample_to (int): if integer and > 0, the points are randomly\n",
    "            subsampled to this value\n",
    "    '''\n",
    "    h, w = resolution\n",
    "    n_points = resolution[0] * resolution[1]\n",
    "\n",
    "    # Arrange pixel location in scale resolution\n",
    "    pixel_locations = torch.meshgrid(torch.arange(0, w), torch.arange(0, h))\n",
    "    pixel_locations = torch.stack(\n",
    "        [pixel_locations[0], pixel_locations[1]],\n",
    "        dim=-1).long().view(1, -1, 2).repeat(batch_size, 1, 1)\n",
    "    pixel_scaled = pixel_locations.clone().float()\n",
    "\n",
    "    # Shift and scale points to match image_range\n",
    "    scale = (image_range[1] - image_range[0])\n",
    "    loc = scale / 2\n",
    "    pixel_scaled[:, :, 0] = scale * pixel_scaled[:, :, 0] / (w - 1) - loc\n",
    "    pixel_scaled[:, :, 1] = scale * pixel_scaled[:, :, 1] / (h - 1) - loc\n",
    "\n",
    "    # Subsample points if subsample_to is not None and > 0\n",
    "    if (subsample_to is not None and subsample_to > 0 and\n",
    "            subsample_to < n_points):\n",
    "        idx = np.random.choice(pixel_scaled.shape[1], size=(subsample_to,),\n",
    "                               replace=False)\n",
    "        pixel_scaled = pixel_scaled[:, idx]\n",
    "        pixel_locations = pixel_locations[:, idx]\n",
    "\n",
    "    if invert_y_axis:\n",
    "        assert(image_range == (-1, 1))\n",
    "        pixel_scaled[..., -1] *= -1.\n",
    "        pixel_locations[..., -1] = (h - 1) - pixel_locations[..., -1]\n",
    "\n",
    "    return pixel_locations, pixel_scaled\n",
    "\n",
    "# 6. mat_mul with intrinsic and then extrinsic gives you p_world (pixels in world) \n",
    "def image_points_to_world(image_points, camera_mat, world_mat, scale_mat=None,\n",
    "                          invert=False, negative_depth=True):\n",
    "    ''' Transforms points on image plane to world coordinates.\n",
    "    In contrast to transform_to_world, no depth value is needed as points on\n",
    "    the image plane have a fixed depth of 1.\n",
    "    Args:\n",
    "        image_points (tensor): image points tensor of size B x N x 2\n",
    "        camera_mat (tensor): camera matrix\n",
    "        world_mat (tensor): world matrix\n",
    "        scale_mat (tensor): scale matrix\n",
    "        invert (bool): whether to invert matrices (default: False)\n",
    "    '''\n",
    "    batch_size, n_pts, dim = image_points.shape\n",
    "    assert(dim == 2)\n",
    "    d_image = torch.ones(batch_size, n_pts, 1)\n",
    "    if negative_depth:\n",
    "        d_image *= -1.\n",
    "    return transform_to_world(image_points, d_image, camera_mat, world_mat,\n",
    "                              scale_mat, invert=invert)\n",
    "\n",
    "def transform_to_world(pixels, depth, camera_mat, world_mat, scale_mat=None,\n",
    "                       invert=True, use_absolute_depth=True):\n",
    "    ''' Transforms pixel positions p with given depth value d to world coordinates.\n",
    "    Args:\n",
    "        pixels (tensor): pixel tensor of size B x N x 2\n",
    "        depth (tensor): depth tensor of size B x N x 1\n",
    "        camera_mat (tensor): camera matrix\n",
    "        world_mat (tensor): world matrix\n",
    "        scale_mat (tensor): scale matrix\n",
    "        invert (bool): whether to invert matrices (default: true)\n",
    "    '''\n",
    "    assert(pixels.shape[-1] == 2)\n",
    "\n",
    "    if scale_mat is None:\n",
    "        scale_mat = torch.eye(4).unsqueeze(0).repeat(\n",
    "            camera_mat.shape[0], 1, 1)\n",
    "\n",
    "    # Convert to pytorch\n",
    "    pixels, is_numpy = to_pytorch(pixels, True)\n",
    "    depth = to_pytorch(depth)\n",
    "    camera_mat = to_pytorch(camera_mat)\n",
    "    world_mat = to_pytorch(world_mat)\n",
    "    scale_mat = to_pytorch(scale_mat)\n",
    "\n",
    "    # Invert camera matrices\n",
    "    if invert:\n",
    "        camera_mat = torch.inverse(camera_mat)\n",
    "        world_mat = torch.inverse(world_mat)\n",
    "        scale_mat = torch.inverse(scale_mat)\n",
    "\n",
    "    # Transform pixels to homogen coordinates\n",
    "    pixels = pixels.permute(0, 2, 1)\n",
    "    pixels = torch.cat([pixels, torch.ones_like(pixels)], dim=1)\n",
    "\n",
    "    # Project pixels into camera space\n",
    "    if use_absolute_depth:\n",
    "        pixels[:, :2] = pixels[:, :2] * depth.permute(0, 2, 1).abs()\n",
    "        pixels[:, 2:3] = pixels[:, 2:3] * depth.permute(0, 2, 1)\n",
    "    else:\n",
    "        pixels[:, :3] = pixels[:, :3] * depth.permute(0, 2, 1)\n",
    "        \n",
    "    # Transform pixels to world space\n",
    "    p_world = scale_mat @ world_mat @ camera_mat @ pixels\n",
    "\n",
    "    # Transform p_world back to 3D coordinates\n",
    "    p_world = p_world[:, :3].permute(0, 2, 1)\n",
    "\n",
    "    if is_numpy:\n",
    "        p_world = p_world.numpy()\n",
    "    return p_world\n",
    "\n",
    "\n",
    "# 7. mat_mul zeros with intrinsic&extrinsic for camera pos (which we alread obtained as loc)\n",
    "def origin_to_world(n_points, camera_mat, world_mat, scale_mat=None,\n",
    "                    invert=False):\n",
    "    ''' Transforms origin (camera location) to world coordinates.\n",
    "    Args:\n",
    "        n_points (int): how often the transformed origin is repeated in the\n",
    "            form (batch_size, n_points, 3)\n",
    "        camera_mat (tensor): camera matrix\n",
    "        world_mat (tensor): world matrix\n",
    "        scale_mat (tensor): scale matrix\n",
    "        invert (bool): whether to invert the matrices (default: false)\n",
    "    '''\n",
    "    \n",
    "    batch_size = camera_mat.shape[0]\n",
    "    device = camera_mat.device\n",
    "    # Create origin in homogen coordinates\n",
    "    p = torch.zeros(batch_size, 4, n_points).to(device)\n",
    "    p[:, -1] = 1.\n",
    "\n",
    "    if scale_mat is None:\n",
    "        scale_mat = torch.eye(4).unsqueeze(\n",
    "            0).repeat(batch_size, 1, 1).to(device)\n",
    "\n",
    "    # Invert matrices\n",
    "    if invert:\n",
    "        camera_mat = torch.inverse(camera_mat)\n",
    "        world_mat = torch.inverse(world_mat)\n",
    "        scale_mat = torch.inverse(scale_mat)\n",
    "        \n",
    "    camera_mat = to_pytorch(camera_mat)\n",
    "    world_mat = to_pytorch(world_mat)\n",
    "    scale_mat = to_pytorch(scale_mat)\n",
    "    \n",
    "    # Apply transformation\n",
    "    p_world = scale_mat @ world_mat @ camera_mat @ p\n",
    "\n",
    "    # Transform points back to 3D coordinates\n",
    "    p_world = p_world[:, :3].permute(0, 2, 1)\n",
    "    return p_world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414ea1ff",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d62aa105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Kai-46/nerfplusplus\n",
    "\n",
    "# 8. intersect sphere for distinguishing fg and bg\n",
    "def intersect_sphere(ray_o, ray_d):\n",
    "    '''\n",
    "    ray_o, ray_d: [..., 3]\n",
    "    compute the depth of the intersection point between this ray and unit sphere\n",
    "    '''\n",
    "    # note: d1 becomes negative if this mid point is behind camera\n",
    "    d1 = -torch.sum(ray_d * ray_o, dim=-1) / torch.sum(ray_d * ray_d, dim=-1)\n",
    "    p = ray_o + d1.unsqueeze(-1) * ray_d\n",
    "    # consider the case where the ray does not intersect the sphere\n",
    "    ray_d_cos = 1. / torch.norm(ray_d, dim=-1)\n",
    "    p_norm_sq = torch.sum(p * p, dim=-1)\n",
    "    if (p_norm_sq >= 1.).any():\n",
    "        raise Exception('Not all your cameras are bounded by the unit sphere; please make sure the cameras are normalized properly!')\n",
    "    d2 = torch.sqrt(1. - p_norm_sq) * ray_d_cos\n",
    "\n",
    "    return d1 + d2\n",
    "\n",
    "# 9. inverse sphere sampling for bg\n",
    "def depth2pts_outside(ray_o, ray_d, depth):\n",
    "    '''\n",
    "    ray_o, ray_d: [..., 3]\n",
    "    depth: [...]; inverse of distance to sphere origin\n",
    "    '''\n",
    "    # note: d1 becomes negative if this mid point is behind camera\n",
    "    d1 = -torch.sum(ray_d * ray_o, dim=-1) / torch.sum(ray_d * ray_d, dim=-1)\n",
    "    p_mid = ray_o + d1.unsqueeze(-1) * ray_d\n",
    "    p_mid_norm = torch.norm(p_mid, dim=-1)\n",
    "    ray_d_cos = 1. / torch.norm(ray_d, dim=-1)\n",
    "    d2 = torch.sqrt(1. - p_mid_norm * p_mid_norm) * ray_d_cos\n",
    "    \n",
    "    p_sphere = ray_o + (d1 + d2).unsqueeze(-1) * ray_d\n",
    "\n",
    "    rot_axis = torch.cross(ray_o, p_sphere, dim=-1)\n",
    "    rot_axis = rot_axis / torch.norm(rot_axis, dim=-1, keepdim=True)\n",
    "    phi = torch.asin(p_mid_norm)\n",
    "    theta = torch.asin(p_mid_norm * depth)  # depth is inside [0, 1]\n",
    "    rot_angle = (phi - theta).unsqueeze(-1)     # [..., 1]\n",
    "\n",
    "    # now rotate p_sphere\n",
    "    # Rodrigues formula: https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula\n",
    "    p_sphere_new = p_sphere * torch.cos(rot_angle) + \\\n",
    "                   torch.cross(rot_axis, p_sphere, dim=-1) * torch.sin(rot_angle) + \\\n",
    "                   rot_axis * torch.sum(rot_axis*p_sphere, dim=-1, keepdim=True) * (1.-torch.cos(rot_angle))\n",
    "    p_sphere_new = p_sphere_new / torch.norm(p_sphere_new, dim=-1, keepdim=True)\n",
    "    pts = torch.cat((p_sphere_new.squeeze(), depth.squeeze().unsqueeze(-1)), dim=-1) # (modified) added .squeeze()\n",
    "\n",
    "    # now calculate conventional depth\n",
    "    depth_real = 1. / (depth + TINY_NUMBER) * torch.cos(theta) * ray_d_cos + d1\n",
    "    return pts, depth_real\n",
    "\n",
    "# 10. perturb sample z values (depth) for some randomness (stratified sampling)\n",
    "def perturb_samples(z_vals):\n",
    "    # get intervals between samples\n",
    "    mids = .5 * (z_vals[..., 1:] + z_vals[..., :-1])\n",
    "    upper = torch.cat([mids, z_vals[..., -1:]], dim=-1)\n",
    "    lower = torch.cat([z_vals[..., 0:1], mids], dim=-1)\n",
    "    # uniform samples in those intervals\n",
    "    t_rand = torch.rand_like(z_vals)\n",
    "    z_vals = lower + (upper - lower) * t_rand  # [N_rays, N_samples]\n",
    "\n",
    "    return z_vals\n",
    "\n",
    "# 11. return fg (just uniform) and bg (uniform inverse sphere) samples\n",
    "def uniformsampling(ray_o, ray_d, min_depth, N_samples, device):\n",
    "    \n",
    "    dots_sh = list(ray_d.shape[:-1])\n",
    "\n",
    "    # foreground depth\n",
    "    fg_far_depth = intersect_sphere(ray_o, ray_d)  # [...,]\n",
    "    fg_near_depth = min_depth  # [..., ]\n",
    "    step = (fg_far_depth - fg_near_depth) / (N_samples - 1)\n",
    "    fg_depth = torch.stack([fg_near_depth + i * step for i in range(N_samples)], dim=-1)  # [..., N_samples]\n",
    "    fg_depth = perturb_samples(fg_depth)   # random perturbation during training\n",
    "\n",
    "    # background depth\n",
    "    bg_depth = torch.linspace(0., 1., N_samples).view(\n",
    "                [1, ] * len(dots_sh) + [N_samples,]).expand(dots_sh + [N_samples,]).to(device)\n",
    "    bg_depth = perturb_samples(bg_depth)   # random perturbation during training\n",
    "\n",
    "\n",
    "    fg_ray_o = ray_o.unsqueeze(-2).expand(dots_sh + [N_samples, 3])\n",
    "    fg_ray_d = ray_d.unsqueeze(-2).expand(dots_sh + [N_samples, 3])\n",
    "\n",
    "    bg_ray_o = ray_o.unsqueeze(-2).expand(dots_sh + [N_samples, 3])\n",
    "    bg_ray_d = ray_d.unsqueeze(-2).expand(dots_sh + [N_samples, 3])\n",
    "    \n",
    "    # sampling foreground\n",
    "    fg_pts = fg_ray_o + fg_depth.unsqueeze(-1) * fg_ray_d\n",
    "\n",
    "    # sampling background\n",
    "    bg_pts, bg_depth_real = depth2pts_outside(bg_ray_o, bg_ray_d, bg_depth)\n",
    "\n",
    "    return fg_pts, bg_pts, bg_depth_real\n",
    "\n",
    "# 12 convert bg pts (x', y', z' 1/r) to real bg pts (x, y, z)\n",
    "def pts2realpts(bg_pts, bg_depth_real):\n",
    "    return bg_pts[:, :, :3] * bg_depth_real.squeeze().unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "856d052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def giraffe(u = 1,\n",
    "            v = 0.5,\n",
    "            r=2.713,\n",
    "            depth_range=[0.5, 6.],\n",
    "            n_ray_samples=16,\n",
    "            resolution_vol = 4,\n",
    "            batch_size = 1\n",
    "           ):\n",
    "\n",
    "    range_radius=[r, r]\n",
    "    \n",
    "    res = resolution_vol\n",
    "    n_points = res * res\n",
    "\n",
    "    # 1. get camera intrinsic \n",
    "    camera_mat = get_camera_mat()\n",
    "\n",
    "    # 2. get camera position with camera pose (theta & phi)\n",
    "    loc = to_sphere(u, v)\n",
    "    loc = torch.tensor(loc).float()\n",
    "    radius = range_radius[0] + \\\n",
    "        torch.rand(batch_size) * (range_radius[1] - range_radius[0])\n",
    "    loc = loc * radius.unsqueeze(-1)\n",
    "\n",
    "    # 3. get camera coordinate system assuming it points to the center of the sphere\n",
    "    R = look_at(loc)\n",
    "\n",
    "    # 4. The carmera coordinate is the rotational matrix and with camera loc, it is camera extrinsic\n",
    "    RT = np.eye(4).reshape(1, 4, 4)\n",
    "    RT[:, :3, :3] = R\n",
    "    RT[:, :3, -1] = loc\n",
    "    world_mat = RT\n",
    "\n",
    "    # 5. arange 2d array of pixel coordinate and give depth of 1\n",
    "    pixels = arange_pixels((res, res), 1, invert_y_axis=False)[1]\n",
    "    pixels[..., -1] *= -1. # still dunno why this is here\n",
    "\n",
    "    # 6. mat_mul with intrinsic and then extrinsic gives you p_world (pixels in world) \n",
    "    pixels_world = image_points_to_world(pixels, camera_mat, world_mat)\n",
    "    \n",
    "    # 7. mat_mul zeros with intrinsic&extrinsic for camera pos (which we alread obtained as loc)\n",
    "    camera_world = origin_to_world(n_points, camera_mat, world_mat)\n",
    "\n",
    "    # 8. ray = pixel - camera origin (in world)\n",
    "    ray_vector = pixels_world - camera_world\n",
    "\n",
    "    # 9. depths from closest to furthest (0.5 ~ 6.0)\n",
    "    di = depth_range[0] + \\\n",
    "        torch.linspace(0., 1., steps=n_ray_samples).reshape(1, 1, -1) * (\n",
    "            depth_range[1] - depth_range[0])\n",
    "    di = di.repeat(batch_size, n_points, 1)\n",
    "\n",
    "    # 10. calculate points\n",
    "    p_i = camera_world.unsqueeze(-2).contiguous() + \\\n",
    "        di.unsqueeze(-1).contiguous() * ray_vector.unsqueeze(-2).contiguous()\n",
    "    \n",
    "    return pixels_world, camera_world, world_mat, p_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a0c73e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nerfpp(u = 1,\n",
    "           v = 0.5,\n",
    "           fov = 49.13,\n",
    "           depth_range=[0.5, 6.],\n",
    "           n_ray_samples=16,\n",
    "           resolution_vol = 4,\n",
    "           batch_size = 1,\n",
    "           device = torch.device('cpu')\n",
    "           ):\n",
    "    \n",
    "    r = 1\n",
    "    range_radius=[r, r]\n",
    "    \n",
    "    res = resolution_vol\n",
    "    n_points = res * res\n",
    "\n",
    "    # 1. get camera intrinsic - fiddle around with fov this time\n",
    "    camera_mat = get_camera_mat(fov=fov)\n",
    "\n",
    "    # 2. get camera position with camera pose (theta & phi)\n",
    "    loc = to_sphere(u, v)\n",
    "    loc = torch.tensor(loc).float()\n",
    "    \n",
    "    radius = range_radius[0] + \\\n",
    "        torch.rand(batch_size) * (range_radius[1] - range_radius[0])\n",
    "    \n",
    "    loc = loc * radius.unsqueeze(-1)\n",
    "\n",
    "    # 3. get camera coordinate system assuming it points to the center of the sphere\n",
    "    R = look_at(loc)\n",
    "\n",
    "    # 4. The carmera coordinate is the rotational matrix and with camera loc, it is camera extrinsic\n",
    "    RT = np.eye(4).reshape(1, 4, 4)\n",
    "    RT[:, :3, :3] = R\n",
    "    RT[:, :3, -1] = loc\n",
    "    world_mat = RT\n",
    "\n",
    "    # 5. arange 2d array of pixel coordinate and give depth of 1\n",
    "    pixels = arange_pixels((res, res), 1, invert_y_axis=False)[1]\n",
    "    pixels[..., -1] *= -1. # still dunno why this is here\n",
    "\n",
    "    # 6. mat_mul with intrinsic and then extrinsic gives you p_world (pixels in world) \n",
    "    pixels_world = image_points_to_world(pixels, camera_mat, world_mat)\n",
    "\n",
    "    # 7. mat_mul zeros with intrinsic&extrinsic for camera pos (which we alread obtained as loc)\n",
    "    camera_world = origin_to_world(n_points, camera_mat, world_mat)\n",
    "\n",
    "    # 8. ray = pixel - camera origin (in world)\n",
    "    ray_vector = pixels_world - camera_world\n",
    "\n",
    "    # 9. sample fg and bg points according to nerfpp (uniform and inverse sphere)\n",
    "    fg_pts, bg_pts, bg_depth_real = uniformsampling(ray_o=camera_world, ray_d=ray_vector, min_depth=depth_range[0], N_samples=n_ray_samples, device=device)\n",
    "    \n",
    "    #10. convert bg pts (x', y', z' 1/r) to real bg pts (x, y, z)\n",
    "    bg_pts_real = pts2realpts(bg_pts, bg_depth_real)\n",
    "    \n",
    "    return pixels_world, camera_world, world_mat, fg_pts, bg_pts_real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd19406",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9dd6b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw sphere with radius r \n",
    "# also draw contours and vertical lines\n",
    "def draw_sphere(r, sphere_colorscale, sphere_opacity):\n",
    "    # sphere\n",
    "    u = np.linspace(0, 2 * np.pi, 100)\n",
    "    v = np.linspace(0, np.pi, 100)\n",
    "    x = r * np.outer(np.cos(u), np.sin(v))\n",
    "    y = r * np.outer(np.sin(u), np.sin(v))\n",
    "    z = r * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "    \n",
    "    # vertical lines on sphere\n",
    "    u2 = np.linspace(0, 2 * np.pi, 20)\n",
    "    x2 = r * np.outer(np.cos(u2), np.sin(v))\n",
    "    y2 = r * np.outer(np.sin(u2), np.sin(v))\n",
    "    z2 = r * np.outer(np.ones(np.size(u2)), np.cos(v))\n",
    "    \n",
    "    # create sphere and draw sphere with contours\n",
    "    fig = go.Figure(data=[go.Surface(x=x, y=y, z=z, \n",
    "                                 colorscale=sphere_colorscale, opacity=sphere_opacity,\n",
    "                                 contours = {\n",
    "                                     'z' : {'show' : True, 'start' : -r,\n",
    "                                           'end' : r, 'size' : r/10,\n",
    "                                           'color' : 'white',\n",
    "                                           'width' : 1}\n",
    "                                 }\n",
    "                                , showscale=False)])\n",
    "    \n",
    "    # vertical lines on sphere\n",
    "    for i in range(len(u2)):\n",
    "        fig.add_scatter3d(x=x2[i], y=y2[i], z=z2[i], \n",
    "                          line=dict(\n",
    "                              color='white',\n",
    "                              width=1\n",
    "                          ),\n",
    "                         mode='lines',\n",
    "                         showlegend=False)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# draw xyplane\n",
    "def draw_XYplane(fig, xy_plane_colorscale, xy_plane_opacity, x_range = [-2, 2], y_range = [-2, 2]):\n",
    "    x3 = np.linspace(x_range[0], x_range[1], 100)\n",
    "    y3 = np.linspace(y_range[0], y_range[1], 100)\n",
    "    z3 = np.zeros(shape=(100,100))\n",
    "    \n",
    "    fig.add_surface(x=x3, y=y3, z=z3,\n",
    "                colorscale =xy_plane_colorscale, opacity=xy_plane_opacity,\n",
    "                showscale=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "    \n",
    "\n",
    "def draw_XYZworld(fig, world_axis_size):\n",
    "    # x, y, z positive direction (world)\n",
    "    X_axis = [0, world_axis_size]\n",
    "    X_text = [None, \"X\"]\n",
    "    X0 = [0, 0]\n",
    "    Y_axis = [0, world_axis_size]\n",
    "    Y_text = [None, \"Y\"]\n",
    "    Y0 = [0, 0]\n",
    "    Z_axis = [0, world_axis_size]\n",
    "    Z_text = [None, \"Z\"]\n",
    "    Z0 = [0, 0]\n",
    "    \n",
    "    fig.add_scatter3d(x=X_axis, y=Y0, z=Z0, \n",
    "                      line=dict(\n",
    "                          color='red',\n",
    "                          width=10\n",
    "                      ),\n",
    "                    mode='lines+text',\n",
    "                    text=X_text,\n",
    "                    textposition='top center',\n",
    "                    textfont=dict(\n",
    "                        color=\"red\",\n",
    "                        size=18\n",
    "                    ),\n",
    "                    showlegend=False)\n",
    "\n",
    "    fig.add_scatter3d(x=X0, y=Y_axis, z=Z0, \n",
    "                          line=dict(\n",
    "                              color='green',\n",
    "                              width=10\n",
    "                          ),\n",
    "                         mode='lines+text',\n",
    "                        text=Y_text,\n",
    "                        textposition='top center',\n",
    "                        textfont=dict(\n",
    "                            color=\"green\",\n",
    "                            size=18\n",
    "                        ),\n",
    "                        showlegend=False)\n",
    "\n",
    "    fig.add_scatter3d(x=X0, y=Y0, z=Z_axis, \n",
    "                          line=dict(\n",
    "                              color='blue',\n",
    "                              width=10\n",
    "                          ),\n",
    "                         mode='lines+text',\n",
    "                        text=Z_text,\n",
    "                        textposition='top center',\n",
    "                        textfont=dict(\n",
    "                            color=\"blue\",\n",
    "                            size=18\n",
    "                        ),\n",
    "                        showlegend=False)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# draw cam and cam coordinate system\n",
    "def draw_cam_init(fig, world_mat, camera_axis_size, camera_color):\n",
    "    # camera at init\n",
    "\n",
    "    Xc = [world_mat[0, : ,3][0]]\n",
    "    Yc = [world_mat[0, : ,3][1]]\n",
    "    Zc = [world_mat[0, : ,3][2]]\n",
    "    text_c = [\"Camera\"]\n",
    "\n",
    "    # camera axis\n",
    "    Xc_Xaxis = Xc + [world_mat[0, : ,0][0]*camera_axis_size+Xc[0]]\n",
    "    Yc_Xaxis = Yc + [world_mat[0, : ,0][1]*camera_axis_size+Yc[0]]\n",
    "    Zc_Xaxis = Zc + [world_mat[0, : ,0][2]*camera_axis_size+Zc[0]]\n",
    "    text_Xaxis = [None, \"Xc\"]\n",
    "    \n",
    "    # -z in world perspective\n",
    "    Xc_Yaxis = Xc + [world_mat[0, : ,1][0]*camera_axis_size+Xc[0]]\n",
    "    Yc_Yaxis = Yc + [world_mat[0, : ,1][1]*camera_axis_size+Yc[0]]\n",
    "    Zc_Yaxis = Zc + [world_mat[0, : ,1][2]*camera_axis_size+Zc[0]]\n",
    "    text_Yaxis = [None, \"Yc\"]\n",
    "\n",
    "    # y in world perspective\n",
    "    Xc_Zaxis = Xc + [world_mat[0, : ,2][0]*camera_axis_size+Xc[0]]\n",
    "    Yc_Zaxis = Yc + [world_mat[0, : ,2][1]*camera_axis_size+Yc[0]]\n",
    "    Zc_Zaxis = Zc + [world_mat[0, : ,2][2]*camera_axis_size+Zc[0]]\n",
    "    text_Zaxis = [None, \"Zc\"]\n",
    "        \n",
    "    # cam pos\n",
    "    fig.add_scatter3d(x=Xc, y=Yc, z=Zc, \n",
    "                     mode='markers',\n",
    "                  marker=dict(\n",
    "                      color=camera_color,\n",
    "                      size=4,\n",
    "                      sizemode='diameter'\n",
    "                  ),\n",
    "                    showlegend=False)\n",
    "\n",
    "    # camera axis\n",
    "    fig.add_scatter3d(x=Xc_Xaxis, y=Yc_Xaxis, z=Zc_Xaxis, \n",
    "                          line=dict(\n",
    "                              color='red',\n",
    "                              width=10\n",
    "                          ),\n",
    "                        mode='lines+text',\n",
    "                        text=text_Xaxis,\n",
    "                        textposition='top center',\n",
    "                        textfont=dict(\n",
    "                            color=\"red\",\n",
    "                            size=18\n",
    "                        ),\n",
    "                        showlegend=False)\n",
    "\n",
    "    fig.add_scatter3d(x=Xc_Yaxis, y=Yc_Yaxis, z=Zc_Yaxis, \n",
    "                          line=dict(\n",
    "                              color='green',\n",
    "                              width=10\n",
    "                          ),\n",
    "                        mode='lines+text',\n",
    "                        text=text_Yaxis,\n",
    "                        textposition='top center',\n",
    "                        textfont=dict(\n",
    "                            color=\"green\",\n",
    "                            size=18\n",
    "                        ),\n",
    "                        showlegend=False)\n",
    "\n",
    "    fig.add_scatter3d(x=Xc_Zaxis, y=Yc_Zaxis, z=Zc_Zaxis, \n",
    "                          line=dict(\n",
    "                              color='blue',\n",
    "                              width=10\n",
    "                          ),\n",
    "                        mode='lines+text',\n",
    "                        text=text_Zaxis,\n",
    "                        textposition='top center',\n",
    "                        textfont=dict(\n",
    "                            color=\"blue\",\n",
    "                            size=18\n",
    "                        ),\n",
    "                        showlegend=False)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# draw all rays\n",
    "def draw_all_rays(fig, p_i, ray_color):\n",
    "    for i in range(p_i.shape[1]):\n",
    "        Xray = p_i[0, i, :, 0]\n",
    "        Yray = p_i[0, i, :, 1]\n",
    "        Zray = p_i[0, i, :, 2]\n",
    "        \n",
    "        fig.add_scatter3d(x=Xray, y=Yray, z=Zray, \n",
    "                          line=dict(\n",
    "                              color=ray_color,\n",
    "                              width=5\n",
    "                          ),\n",
    "                         mode='lines',\n",
    "                        showlegend=False)\n",
    "        \n",
    "    return fig\n",
    "\n",
    "# draw all rays\n",
    "def draw_all_rays_with_marker(fig, p_i, marker_size, ray_color):\n",
    "    \n",
    "    # convert colorscale string to px.colors.seqeuntial\n",
    "    # default color is set to Viridis in case of mismatch\n",
    "    c = px.colors.sequential.Viridis\n",
    "\n",
    "    for c_name in [ray_color, ray_color.capitalize()]:\n",
    "        try:\n",
    "            c = getattr(px.colors.sequential, c_name)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    for i in range(p_i.shape[1]):\n",
    "        Xray = p_i[0, i, :, 0]\n",
    "        Yray = p_i[0, i, :, 1]\n",
    "        Zray = p_i[0, i, :, 2]\n",
    "        \n",
    "        fig.add_scatter3d(x=Xray, y=Yray, z=Zray, \n",
    "                          \n",
    "                          marker=dict(\n",
    "#                               color=np.arange(len(Xray)),\n",
    "                              color=c,\n",
    "#                               colorscale='Viridis',\n",
    "                              size=marker_size\n",
    "                          ),\n",
    "                          \n",
    "                          line=dict(\n",
    "#                               color=np.arange(len(Xray)),\n",
    "                              color=c,\n",
    "#                               colorscale='Viridis',\n",
    "                              width=3\n",
    "                          ),\n",
    "                         mode=\"lines+markers\",\n",
    "                        showlegend=False)\n",
    "        \n",
    "    return fig\n",
    "\n",
    "# draw near&far frustrum with rays connecting the corners (changed for nerfpp)\n",
    "def draw_ray_frus(fig, p_i, frustrum_color, frustrum_opacity, at=[0, -1]):\n",
    "    \n",
    "    for i in at:\n",
    "#         Xfrus = p_i[0, :, i, 0][[0,1,2,3,7,11,15,14,13,12,8,4,0]]\n",
    "#         Yfrus = p_i[0, :, i, 1][[0,1,2,3,7,11,15,14,13,12,8,4,0]]\n",
    "#         Zfrus = p_i[0, :, i, 2][[0,1,2,3,7,11,15,14,13,12,8,4,0]]\n",
    "\n",
    "        Xfrus = p_i[0, :, i, 0]\n",
    "        Yfrus = p_i[0, :, i, 1]\n",
    "        Zfrus = p_i[0, :, i, 2]\n",
    "        \n",
    "        fig.add_scatter3d(x=Xfrus, y=Yfrus, z=Zfrus, \n",
    "                        line=dict(\n",
    "                              color=frustrum_color,\n",
    "                              width=5\n",
    "                          ),\n",
    "                         mode='lines',\n",
    "                          surfaceaxis=0,\n",
    "                          surfacecolor=frustrum_color,\n",
    "                          opacity=frustrum_opacity,\n",
    "                        showlegend=False)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# draw foreground sample points, ray and frustrum\n",
    "def draw_foreground(fig, fg_pts, fg_color, marker_size, at=[0, -1]):\n",
    "    fig = draw_all_rays_with_marker(fig, fg_pts, marker_size, fg_color)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# draw background sample points, ray and frustrum\n",
    "def draw_background(fig, bg_pts, bg_color, marker_size, at=[0, -1]):\n",
    "    fig = draw_all_rays_with_marker(fig, bg_pts, marker_size, bg_color)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f12fecdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laphi\\AppData\\Local\\Temp/ipykernel_24504/3891967274.py:2: UserWarning: \n",
      "The dash_core_components package is deprecated. Please replace\n",
      "`import dash_core_components as dcc` with `from dash import dcc`\n",
      "  import dash_core_components as dcc\n",
      "C:\\Users\\laphi\\AppData\\Local\\Temp/ipykernel_24504/3891967274.py:3: UserWarning: \n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "  import dash_html_components as html\n"
     ]
    }
   ],
   "source": [
    "from jupyter_dash import JupyterDash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "# for colors\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5e28428",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\laphi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\jupyter_dash\\jupyter_app.py:139: UserWarning:\n",
      "\n",
      "The 'environ['werkzeug.server.shutdown']' function is deprecated and will be removed in Werkzeug 2.1.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x174f9413ac0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app = JupyterDash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Nerfplusplus ray sampling visualization\"),\n",
    "    dcc.Graph(id='graph'),\n",
    "    \n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            \n",
    "            # changes to setting and ray casted \n",
    "            html.Label([ \"u (theta)\",\n",
    "                dcc.Slider(\n",
    "                    id='u-slider', \n",
    "                    min=0, max=1,\n",
    "                    value=0.00,\n",
    "                    marks={str(val) : str(val) for val in [0.00, 0.25, 0.50, 0.75]},\n",
    "                    step=0.01, tooltip = { 'always_visible': True }\n",
    "                ), ]),\n",
    "            html.Label([ \"v (phi)\",\n",
    "                dcc.Slider(\n",
    "                    id='v-slider', \n",
    "                    min=0, max=1,\n",
    "                    value=0.25,\n",
    "                    marks={str(val) : str(val) for val in [0.00, 0.25, 0.50, 0.75]},\n",
    "                    step=0.01, tooltip = { 'always_visible': True }\n",
    "                ), ]),\n",
    "            html.Label([ \"fov (field-of-view))\",\n",
    "                dcc.Slider(\n",
    "                    id='fov-slider', \n",
    "                    min=0, max=100,\n",
    "                    value=50,\n",
    "                    marks={str(val) : str(val) for val in [0, 20, 40, 60, 80, 100]},\n",
    "                    step=5, tooltip = { 'always_visible': True }\n",
    "                ), ]),\n",
    "            html.Label([ \"foreground near depth\",\n",
    "                dcc.Slider(\n",
    "                    id='foreground-near-depth-slider', \n",
    "                    min=0, max=2,\n",
    "                    value=0.5,\n",
    "                    marks={f\"{val:.1f}\" : f\"{val:.1f}\" for val in [0.1 * i for i in range(21)]},\n",
    "                    step=0.1, tooltip = { 'always_visible': True }\n",
    "                ), ])\n",
    "        ], style = {'width' : '48%', 'display' : 'inline-block'}),\n",
    "        \n",
    "        html.Div([\n",
    "            # changes to visual appearance\n",
    "            \n",
    "            # axis scale\n",
    "            html.Div([\n",
    "                html.Label([ \"world axis size\",\n",
    "                    html.Div([\n",
    "                        dcc.Input(id='world-axis-size-input',\n",
    "                                  value=1.5,\n",
    "                                  type='number', style={'width': '50%'}\n",
    "                                 )\n",
    "                    ]),\n",
    "                ], style = {'width' : '34%', 'float' : 'left', 'display' : 'inline-block'}),\n",
    "                html.Label([ \"camera axis size\",\n",
    "                    html.Div([\n",
    "                        dcc.Input(id='camera-axis-size-input',\n",
    "                                  value=0.3,\n",
    "                                  type='number', style={'width': '50%'}\n",
    "                                 )\n",
    "                    ]),\n",
    "                ], style = {'width' : '34%', 'float' : 'left', 'display' : 'inline-block'}),\n",
    "                html.Label([ \"sample marker size\",\n",
    "                    html.Div([\n",
    "                        dcc.Input(id='sample-marker-size-input',\n",
    "                                  value=2,\n",
    "                                  type='number', style={'width': '50%'}\n",
    "                                 )\n",
    "                    ]),\n",
    "                ], style = {'width' : '32%', 'float' : 'left', 'display' : 'inline-block'}),\n",
    "            ]),\n",
    "            \n",
    "            # opacity \n",
    "            html.Div([\n",
    "                html.Label([ \"sphere opacity\",\n",
    "                    html.Div([\n",
    "                        dcc.Input(id='sphere-opacity-input',\n",
    "                                  value=0.2,\n",
    "                                  type='number', style={'width': '50%'}\n",
    "                                 )\n",
    "                    ])\n",
    "                ], style = {'width' : '34%', 'float' : 'left', 'display' : 'inline-block'}),\n",
    "                            \n",
    "                html.Label([ \"xy-plane opacity\",            \n",
    "                    html.Div([\n",
    "                        dcc.Input(id='xy-plane-opacity-input',\n",
    "                                  value=0.8,\n",
    "                                  type='number', style={'width': '50%'}\n",
    "                                 )\n",
    "                    ])\n",
    "                ],  style = {'width' : '34%', 'float' : 'left', 'display' : 'inline-block'}),\n",
    "                \n",
    "            ]),\n",
    "            \n",
    "            # color\n",
    "            html.Div([\n",
    "                html.Label([ \"camera color\",\n",
    "                html.Div([\n",
    "                    dcc.Dropdown(id='camera-color-input',\n",
    "                                 clearable=False,\n",
    "                              value='yellow',\n",
    "                              options=[\n",
    "                                     {'label': c, 'value': c}\n",
    "                                     for (c, _) in mcolors.CSS4_COLORS.items()\n",
    "                                 ], style={'width': '80%'}\n",
    "                             )\n",
    "                ])\n",
    "                ],  style = {'width' : '34%', 'float' : 'left', 'display' : 'inline-block'}),\n",
    "                \n",
    "                html.Label([ \"foreground color\",\n",
    "                    html.Div([\n",
    "                        dcc.Dropdown(id='fg-color-input',\n",
    "                                     clearable=False,\n",
    "                                  value='plotly3',\n",
    "                                  options=[\n",
    "                                         {'label': c, 'value': c}\n",
    "                                         for c in px.colors.named_colorscales()\n",
    "                                     ], style={'width': '80%'}\n",
    "                                 )\n",
    "                    ])\n",
    "                ],  style = {'width' : '34%', 'float' : 'left', 'display' : 'inline-block'}),\n",
    "                \n",
    "                html.Label([ \"background color\",\n",
    "                    html.Div([\n",
    "                        dcc.Dropdown(id='bg-color-input',\n",
    "                                     clearable=False,\n",
    "                                  value='plotly3',\n",
    "                                  options=[\n",
    "                                         {'label': c, 'value': c}\n",
    "                                         for c in px.colors.named_colorscales()\n",
    "                                     ], style={'width': '80%'}\n",
    "                                 )\n",
    "                    ])\n",
    "                ],  style = {'width' : '32%', 'float' : 'left', 'display' : 'inline-block'}),\n",
    "            ]),\n",
    "            \n",
    "            # colorscale\n",
    "            html.Div([\n",
    "                html.Label([ \"sphere colorscale\",\n",
    "                    html.Div([\n",
    "                        dcc.Dropdown(id='sphere-colorscale-input',\n",
    "                                     clearable=False,\n",
    "                                     value='greys',\n",
    "                                     options=[\n",
    "                                         {'label': c, 'value': c}\n",
    "                                         for c in px.colors.named_colorscales()\n",
    "                                     ], style={'width': '80%'}\n",
    "                                    )\n",
    "                    ])\n",
    "                ], style = {'width' : '32%', 'float' : 'left', 'display' : 'inline-block'}),\n",
    "                \n",
    "                html.Label([ \"xy-plane colorscale\",\n",
    "                    html.Div([\n",
    "                        dcc.Dropdown(id='xy-plane-colorscale-input',\n",
    "                                     clearable=False,\n",
    "                                     value='greys',\n",
    "                                     options=[\n",
    "                                         {'label': c, 'value': c}\n",
    "                                         for c in px.colors.named_colorscales()\n",
    "                                     ], style={'width': '80%'}\n",
    "                                    )\n",
    "                    ])\n",
    "                ],  style = {'width' : '34%', 'float' : 'left', 'display' : 'inline-block'}),\n",
    "                \n",
    "                html.Label([ \" \",\n",
    "                    html.Div([\n",
    "                        dcc.Checklist(id='show-background-checklist',\n",
    "                                      \n",
    "                                     options=[\n",
    "                                         {'label': 'show background', 'value': 'show_background'}\n",
    "                                     ], style={'width': '80%'},\n",
    "                                      value=[],\n",
    "                                    )\n",
    "                    ])\n",
    "                ],  style = {'width' : '34%', 'float' : 'left', 'display' : 'inline-block'}),\n",
    "                \n",
    "            ]),\n",
    "            \n",
    "            \n",
    "            \n",
    "        ], style = {'width' : '48%', 'float' : 'right', 'display' : 'inline-block'}),\n",
    "            \n",
    "    ]),\n",
    "    \n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('graph', 'figure'),\n",
    "    Input(\"u-slider\", \"value\"),\n",
    "    Input(\"v-slider\", \"value\"),\n",
    "    \n",
    "    Input(\"fov-slider\", \"value\"),\n",
    "    Input(\"foreground-near-depth-slider\", \"value\"),\n",
    "    \n",
    "    Input(\"world-axis-size-input\", \"value\"),\n",
    "    Input(\"camera-axis-size-input\", \"value\"),\n",
    "    Input(\"sample-marker-size-input\", \"value\"),\n",
    "    \n",
    "    Input(\"camera-color-input\", \"value\"),\n",
    "    Input(\"fg-color-input\", \"value\"),\n",
    "    Input(\"bg-color-input\", \"value\"),\n",
    "    \n",
    "    Input('sphere-colorscale-input', \"value\"),\n",
    "    Input('xy-plane-colorscale-input', \"value\"),\n",
    "    Input('show-background-checklist', \"value\"),\n",
    "       \n",
    "    Input(\"sphere-opacity-input\", \"value\"),\n",
    "    Input(\"xy-plane-opacity-input\", \"value\"),\n",
    ")\n",
    "\n",
    "def update_figure(u, v, \n",
    "                  fov, foreground_near_depth,\n",
    "                  world_axis_size, camera_axis_size, sample_marker_size,\n",
    "                  camera_color, fg_color, bg_color,\n",
    "                  sphere_colorscale, xy_plane_colorscale, show_background,\n",
    "                  sphere_opacity, xy_plane_opacity                  \n",
    "                 ):\n",
    "    \n",
    "    depth_range = [foreground_near_depth, 2]\n",
    "    \n",
    "    # sphere\n",
    "    fig = draw_sphere(r=1, sphere_colorscale=sphere_colorscale, sphere_opacity=sphere_opacity)\n",
    "\n",
    "    # change figure size\n",
    "#     fig.update_layout(autosize=False, width = 500, height=500)\n",
    "\n",
    "    # draw axes in proportion to the proportion of their ranges\n",
    "    fig.update_layout(scene_aspectmode='data')\n",
    "\n",
    "    # xy plane\n",
    "    fig = draw_XYplane(fig, xy_plane_colorscale, xy_plane_opacity,\n",
    "                       x_range=[-depth_range[1], depth_range[1]], y_range=[-depth_range[1], depth_range[1]])\n",
    "\n",
    "    # show world coordinate system (X, Y, Z positive direction)\n",
    "    fig = draw_XYZworld(fig, world_axis_size=world_axis_size)\n",
    "\n",
    "    pixels_world, camera_world, world_mat, fg_pts, bg_pts = nerfpp(u=u, v=v, fov=fov, depth_range=depth_range)\n",
    "\n",
    "    #  draw camera at init (with its cooridnate system)\n",
    "    fig = draw_cam_init(fig, world_mat, \n",
    "                        camera_axis_size=camera_axis_size, camera_color=camera_color)\n",
    "\n",
    "    # draw foreground and background sample point, ray, and frustrum\n",
    "    fig = draw_foreground(fig, fg_pts, fg_color, sample_marker_size, at=[0, -1])\n",
    "    \n",
    "    if show_background:\n",
    "        fig = draw_background(fig, bg_pts.unsqueeze(0), bg_color, sample_marker_size, at=[0, -1])\n",
    "    \n",
    "    return fig\n",
    "\n",
    "app.run_server(mode='inline')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
